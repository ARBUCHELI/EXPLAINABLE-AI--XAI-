# EXPLAINABLE AI
----------------

* What is Explainable AI?
-------------------------
Learn about Explainable AI and its importance in understanding the inner workings of deep learning systems.

Key ideas:

	. Explainable AI (XAI) is a set of techniques used to make the inner workings of deep learning systems transparent and understandable to humans.
	---------------

	. Some AI algorithms, like decision trees, are called inherently explainable. Due to their structure, it is possible (at least in theory) for human experts to understand how these 
	algorithms make decisions.

	. Other AI algorithms, like deep neural networks, are inherently opaque. Sometimes called black boxes, these algorithms can be highly effective, but it is usually very hard to 
	understand how they are working.

	. The goal of Explainable AI is to make black boxes into glass boxes, providing transparency into the decision-making process of deep learning systems.

* Instructions
--------------
Think about the following question as you watch the video. When you are ready to move on, select Next.

Question: why do you think we care about explainability at all, if the algorithms work?
---------

* See our answer
----------------
	. Imagine an algorithm being used to diagnose a medical condition. A human doctor has all sorts of factors that influence their decision, including judgement calls like "better to 
	err on the side of caution." If we want the algorithm to do the same, we need to know how the algorithm is making its decisions!

	. Algorithms are also only as good as their data. If the data being fed into the algorithm is biased, the algorithm may reproduce that bias. Medical datasets, for example, often 
	don't contain the same amount or quality of data for different types of bodies. So our medical diagnostic algorithm may be influenced by biases in its dataset. Without knowing how 
	it is making decisions, we will have a much harder time correcting for these issues.

	. For more details, see our article Dangers of the Black Box

- Explainable AI (XAI)
----------------------

	. Inherently Explainable Algorithms
	-----------------------------------
		. Decision trees
		. Regression algorithms
		. Bayesian classifiers
		. Support vector machines

	. Inherently Opaque Algorithms
	------------------------------
		. Deep Learning Algorithms
		. Genetic Algorithms
		

------------------------------------------------------------------------------------------------------------------------------------------------------------------

* The Interpretability Problem
------------------------------
Learn about the interpretability problem and how deep learning systems store knowledge and make decisions.

Key ideas:

	. The interpretability problem is the challenge of explaining the inner workings of a deep learning system.

	. In a deep learning system, knowledge implicit in the training data is reflected in changes to the structure of its hidden layers.

	. Different inputs activate different groups of neurons or activation paths within these layers, resulting in different outputs or decisions.
	
	. So understanding the structure of hidden layers can help us understand how a deep learning system stores knowledge and makes decisions.

	. There are three main approaches to studying deep learning systems: constraint, perturbation, and generative adversarial networks (GANS). We’ll learn more about each of these in 
	later videos.

* Instructions
--------------
Think about the following question as you watch the video. When you are ready to move on, select Next.

Question: how does the example deep learning system store conceptual information, like the idea of a “triangle”?

* See our answer
----------------
Concepts correspond to groups of nodes that are activated by a class of inputs. For example, the group of nodes that is activated whenever a triangle is fed into the neural network 
represent the concept of "triangle". By understanding how different inputs activate different groups of neurons, we can gain insight into where and how concepts are stored inside the 
hidden layers, and begin to explain how the deep learning system makes its decisions!


------------------------------------------------------------------------------------------------------------------------------------------------------------------












































































